{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Reefer Container Shipment Order Management Service Abstract This project is demonstrating, one of the possible implementation of the Command Query Responsibility Segregation and event sourcing patterns applied to container shipment order management service. It is part of the Event Driven Architecture solution implementation reference architecture. From a use case point of view, it implements the order management component, responsible to manage the full life cycle of a shipment order issued by a manufacturer who want to ship fresh goods overseas. The business process is defined here . One of the business requirements for adopting event sourcing and CQRS patterns is to be able to get visibility to the history of orders and track the good shipment progress over time. This would include the ability to determine: How frequently does an order get cancelled after it is placed but before an empty container is delivered to pick up location or loaded ? How often does an order get cancelled after the order is confirmed, a container assigned and goods loaded into it? What are all events for a particular order and associated container shipment? Has the cold chain been protected on this particular order? How long it takes to deliver a container to pick up location? To answer those questions we need to keep historical information of each orders and its events. Event sourcing is to pattern of choice for that. We are detailing how to go from event storming to implementation in a separate note by apply the domain-driven design approach. Implementation approach As introduced in the high level design note the order entity life cycle looks like in the following diagram: The order microservice supports the implementations of this life cycle, using event sourcing and CQRS patter. With CQRS we separate the 'write model' from the read. The Command microservice implements the write model and exposes a set of REST end points for Creating Order, Updating Order and getting Order per ID. The query service will address complex queries to support adhoc business requirements and joining data between different entities like the order, the containers and the voyages. So we have two Java projects to support each service implementation. Each service is packaged as container and deployable to Kubernetes. Order command microservice Order query microservice As some requirements are related to historical query, using an event approach we need to keep all the events related to what happens to the order. Instead of implementing a complex logic with the query and command services the event sourcing is supported by using Kafka topics. The following diagram illustrates the CQRS and event sourcing applied to the order management service. Client to the REST api, like a back end for front end app, performs a HTTP POST operation with the order data. The command generates events and persists order on its own data source. The query part is an event consumer and defines its own data projections to support the different queries: The datasource at the command level, may not be necessary, but we want to illustrate here the fact that it is possible to have a SQL based database or a document oriented database to keep the order last state: a call to get /orders/{id} will return the current order state. For the query part the projection can be kept in memory or persisted on its own data store. The decision to go for in memory ro database depends upon the amount of data to join, and the time horizon set at the Kafka topic level. A service may always rebuild its view by re-reading the topic from the beginning. An alternate solution is to have the BFF pushing events to the event source and then having the order service consuming event to persist them, as illustrated in the following diagram: As the BFF still needs to get order by ID or perform complex query it has to access the order service using HTTP, we could imagine the BFF developers prefer to use one communication protocol and adding kafka producer was not their cup of tea. The following sequence diagram illustrates the relationships between the components. To avoid transaction between the database update and the event published, the choice is to publish the event as soon as it is received and use a consumer inside the command service to load the data and save to the database. The kafka topic act as a source of trust for this service. This is illustrated in this article. The /order POST REST end point source code is here and the order events consumer in the command pattern. See the class OrderCRUDService.java . Produce order events to the orders topic. Consume events to update the state of the order or enrich it with new elements. When the application starts there is a ServletContextListener class started to create a consumer to subscribe to order events (different types) from orders topic. When consumer reaches an issue to get event it creates an error to the errors topic, so administrator user could replay the event source from the last committed offset. Any kafka broker communication issue is shutting down the consumer loop. Data and Event Model By applying a domain-driven design we can identify aggregates, entities, value objects and domain events. Those elements help us to be our information model as classes. For any event-driven microservice you need to assess what data to carry in the event and what persist in the potential data source. The following diagram illustrates the different data models in the context of this order microservice: The Order entered in the User interface is defined like: class Address { street : string ; city : string ; country : string ; state : string ; zipcode : string ; } class Order { orderID : string ; customerID : string ; pickupAddress : Address ; destinationAddress : Address ; productID : string ; quantity : string ; expectedDeliveryDate : string ; // date as ISO format } The information to persist in the database may be used to do analytics, and get the last status of order. It may look use relational database and may have information like: class Address { street : string ; city : string ; country : string ; state : string ; zipcode : string ; } class Order { orderID : string ; customerID : string ; pickupAddress : Address ; destinationAddress : Address ; productID : string ; quantity : string ; expectedDeliveryDate : string ; // date as ISO format pickupDate : string ; // date as ISO format } class OrderContainers { orderID : string ; containerID : string []; } On the event side we may generate OrderCreated, OrderCancelled,... But what is in the event payload? We can propose the following structure where type will help to specify the event type and getting a generic payload we can have anything in it. class OrderEvent { orderId : string ; timestamp : string ; // date as ISO format payload : any ; type : string ; version : string ; } Also do we need to ensure consistency between those data views? Where is the source of truth? In traditional SOA service with application maintaining all the tables and beans to support all the business requirements, ACID transactions support the consistency and integrity of the data, and the database is one source of truth. With microservices responsible to manage its own business entity, clearly separated from other business entities, data eventual consistency is the standard. If you want to read more about the Event Sourcing and CQRS patterns see this article.","title":"Implementation considerations"},{"location":"#reefer-container-shipment-order-management-service","text":"Abstract This project is demonstrating, one of the possible implementation of the Command Query Responsibility Segregation and event sourcing patterns applied to container shipment order management service. It is part of the Event Driven Architecture solution implementation reference architecture. From a use case point of view, it implements the order management component, responsible to manage the full life cycle of a shipment order issued by a manufacturer who want to ship fresh goods overseas. The business process is defined here . One of the business requirements for adopting event sourcing and CQRS patterns is to be able to get visibility to the history of orders and track the good shipment progress over time. This would include the ability to determine: How frequently does an order get cancelled after it is placed but before an empty container is delivered to pick up location or loaded ? How often does an order get cancelled after the order is confirmed, a container assigned and goods loaded into it? What are all events for a particular order and associated container shipment? Has the cold chain been protected on this particular order? How long it takes to deliver a container to pick up location? To answer those questions we need to keep historical information of each orders and its events. Event sourcing is to pattern of choice for that. We are detailing how to go from event storming to implementation in a separate note by apply the domain-driven design approach.","title":"Reefer Container Shipment Order Management Service"},{"location":"#implementation-approach","text":"As introduced in the high level design note the order entity life cycle looks like in the following diagram: The order microservice supports the implementations of this life cycle, using event sourcing and CQRS patter. With CQRS we separate the 'write model' from the read. The Command microservice implements the write model and exposes a set of REST end points for Creating Order, Updating Order and getting Order per ID. The query service will address complex queries to support adhoc business requirements and joining data between different entities like the order, the containers and the voyages. So we have two Java projects to support each service implementation. Each service is packaged as container and deployable to Kubernetes. Order command microservice Order query microservice As some requirements are related to historical query, using an event approach we need to keep all the events related to what happens to the order. Instead of implementing a complex logic with the query and command services the event sourcing is supported by using Kafka topics. The following diagram illustrates the CQRS and event sourcing applied to the order management service. Client to the REST api, like a back end for front end app, performs a HTTP POST operation with the order data. The command generates events and persists order on its own data source. The query part is an event consumer and defines its own data projections to support the different queries: The datasource at the command level, may not be necessary, but we want to illustrate here the fact that it is possible to have a SQL based database or a document oriented database to keep the order last state: a call to get /orders/{id} will return the current order state. For the query part the projection can be kept in memory or persisted on its own data store. The decision to go for in memory ro database depends upon the amount of data to join, and the time horizon set at the Kafka topic level. A service may always rebuild its view by re-reading the topic from the beginning. An alternate solution is to have the BFF pushing events to the event source and then having the order service consuming event to persist them, as illustrated in the following diagram: As the BFF still needs to get order by ID or perform complex query it has to access the order service using HTTP, we could imagine the BFF developers prefer to use one communication protocol and adding kafka producer was not their cup of tea. The following sequence diagram illustrates the relationships between the components. To avoid transaction between the database update and the event published, the choice is to publish the event as soon as it is received and use a consumer inside the command service to load the data and save to the database. The kafka topic act as a source of trust for this service. This is illustrated in this article. The /order POST REST end point source code is here and the order events consumer in the command pattern. See the class OrderCRUDService.java . Produce order events to the orders topic. Consume events to update the state of the order or enrich it with new elements. When the application starts there is a ServletContextListener class started to create a consumer to subscribe to order events (different types) from orders topic. When consumer reaches an issue to get event it creates an error to the errors topic, so administrator user could replay the event source from the last committed offset. Any kafka broker communication issue is shutting down the consumer loop.","title":"Implementation approach"},{"location":"#data-and-event-model","text":"By applying a domain-driven design we can identify aggregates, entities, value objects and domain events. Those elements help us to be our information model as classes. For any event-driven microservice you need to assess what data to carry in the event and what persist in the potential data source. The following diagram illustrates the different data models in the context of this order microservice: The Order entered in the User interface is defined like: class Address { street : string ; city : string ; country : string ; state : string ; zipcode : string ; } class Order { orderID : string ; customerID : string ; pickupAddress : Address ; destinationAddress : Address ; productID : string ; quantity : string ; expectedDeliveryDate : string ; // date as ISO format } The information to persist in the database may be used to do analytics, and get the last status of order. It may look use relational database and may have information like: class Address { street : string ; city : string ; country : string ; state : string ; zipcode : string ; } class Order { orderID : string ; customerID : string ; pickupAddress : Address ; destinationAddress : Address ; productID : string ; quantity : string ; expectedDeliveryDate : string ; // date as ISO format pickupDate : string ; // date as ISO format } class OrderContainers { orderID : string ; containerID : string []; } On the event side we may generate OrderCreated, OrderCancelled,... But what is in the event payload? We can propose the following structure where type will help to specify the event type and getting a generic payload we can have anything in it. class OrderEvent { orderId : string ; timestamp : string ; // date as ISO format payload : any ; type : string ; version : string ; } Also do we need to ensure consistency between those data views? Where is the source of truth? In traditional SOA service with application maintaining all the tables and beans to support all the business requirements, ACID transactions support the consistency and integrity of the data, and the database is one source of truth. With microservices responsible to manage its own business entity, clearly separated from other business entities, data eventual consistency is the standard. If you want to read more about the Event Sourcing and CQRS patterns see this article.","title":"Data and Event Model"},{"location":"build-run/","text":"Build and run the solution locally You have different deployment models: local with docker-compose, minikube, kubernetes on IBM Cloud (IKS), or IBM Cloud private. Each script accepts an argument: LOCAL (default is argument is omitted) MINIKUBE IBM_CLOUD ICP This variable is really used in a set environment script under the refarch-kc project and the scripts folder, as it defines different values for the target environment. Pre-requisites You can have the following software already installed on your computer or use our docker image to get those dependencies integrated in a docker image, which you can use to build, test and package the java programs. Maven Java 8: Any compliant JVM should work. Java 8 JDK from Oracle Java 8 JDK from IBM (AIX, Linux, z/OS, IBM i) , or Download a Liberty server package that contains the IBM JDK (Windows, Linux) Build You need to build each microservices independently using maven Each microservice has its build script to perform the maven package and build the docker image. See scripts folder under each project. For order-command-ms cd order-command-ms ./scripts/buildDocker.sh MINIKUBE For order-query-ms ./scripts/buildDocker.sh MINIKUBE Note The build scripts test if the javatool docker image exist and they use it, if it found. If not they use maven. If you want to use docker compose use LOCAL as parameter. Verify the docker images are created docker images ibmcase/kc-orderqueryms latest b85b43980f35 531MB ibmcase/kc-ordercommandms latest Run On Minikube For the order command microservice: cd order-command-ms helm install chart/ordercommandms/ --name ordercmd --set image.repository=ibmcase/kc-ordercommandms --set image.pullSecret= --set image.pullPolicy=Never --set eventstreams.brokers=kafkabitmani:9092 --set eventstreams.env=MINIKUBE --namespace greencompute or use the command: ./scripts/deployHelm MINIKUBE Without any previously tests done, the call below should return an empty array: [] curl http://localhost:31200/orders With docker compose To run the complete solution locally we use docker compose from the root project. And to stop everything: docker-compose -f kc-solution-compose.yml down docker-compose -f backbone-compose.yml down","title":"Build and run locally"},{"location":"build-run/#build-and-run-the-solution-locally","text":"You have different deployment models: local with docker-compose, minikube, kubernetes on IBM Cloud (IKS), or IBM Cloud private. Each script accepts an argument: LOCAL (default is argument is omitted) MINIKUBE IBM_CLOUD ICP This variable is really used in a set environment script under the refarch-kc project and the scripts folder, as it defines different values for the target environment.","title":"Build and run the solution locally"},{"location":"build-run/#pre-requisites","text":"You can have the following software already installed on your computer or use our docker image to get those dependencies integrated in a docker image, which you can use to build, test and package the java programs. Maven Java 8: Any compliant JVM should work. Java 8 JDK from Oracle Java 8 JDK from IBM (AIX, Linux, z/OS, IBM i) , or Download a Liberty server package that contains the IBM JDK (Windows, Linux)","title":"Pre-requisites"},{"location":"build-run/#build","text":"You need to build each microservices independently using maven Each microservice has its build script to perform the maven package and build the docker image. See scripts folder under each project. For order-command-ms cd order-command-ms ./scripts/buildDocker.sh MINIKUBE For order-query-ms ./scripts/buildDocker.sh MINIKUBE Note The build scripts test if the javatool docker image exist and they use it, if it found. If not they use maven. If you want to use docker compose use LOCAL as parameter. Verify the docker images are created docker images ibmcase/kc-orderqueryms latest b85b43980f35 531MB ibmcase/kc-ordercommandms latest","title":"Build"},{"location":"build-run/#run","text":"","title":"Run"},{"location":"build-run/#on-minikube","text":"For the order command microservice: cd order-command-ms helm install chart/ordercommandms/ --name ordercmd --set image.repository=ibmcase/kc-ordercommandms --set image.pullSecret= --set image.pullPolicy=Never --set eventstreams.brokers=kafkabitmani:9092 --set eventstreams.env=MINIKUBE --namespace greencompute or use the command: ./scripts/deployHelm MINIKUBE Without any previously tests done, the call below should return an empty array: [] curl http://localhost:31200/orders","title":"On Minikube"},{"location":"build-run/#with-docker-compose","text":"To run the complete solution locally we use docker compose from the root project. And to stop everything: docker-compose -f kc-solution-compose.yml down docker-compose -f backbone-compose.yml down","title":"With docker compose"},{"location":"ddd-applied/","text":"Domain-driven design applied to order context During the event storming analysis, we define the domain to be the container shipment domain. It groups a set of subdomains like orders, contract, shipping, and external systems as the voyage scheduling and the container inventory management: Notice that at this time just three physical systems exist. The grouping of the orders, contract and shipping in one boundary context was an analysis shortcut as we want to clearly separate them as the owner ship and ubiquituous language are differents. We have three subdomain and all can be considered core domains. They are competitive advantages and directly impact the organization business. The order subdomain interacts with the contract subdomain via acceptance of the contract conditions from the customer and by build a contract from the created order. When the contract is accepted, the order needs to be shipped, but to do so the shipping subdomain needs to interact with the voyage subsystem to get the available voyage from the closed harbor from the pickup destination, to a target harbor to the shipping destination. It also needs to interact with the container inventory service to get a matching container. Bounded Contexts Within a business context every use of a given domain term, phrase, or sentence, the Ubiquitous Language inside the boundary has a specific contextual meaning. So order context is a boundary context and addresses order, ordered product type, pickup and shipping addresses. The business problem to address is how to make order traceability more efficient so customers have a clear view of their orders. An order will be assigned to one or many containers and containers are assigned to a voyage. User stories The business requirements is presented in this note The following user stories are done in this project: [ ] As a manufacturer manager I want to enter container shipment order information like product reference, quantity, pickup from address, earliest pickup date, shipment to address, shipment by date, and required temperature in transit range so the shipping company can give me back an order confirmation ( including the orderID), expected pickup and delivery dates, the assigned voyage and ship name As the microservice will not have a dedicated UI, we are using the demonstration UI to define forms to gather the data. So this user story is implemented in the kc-ui project, and in this microservice we need to offer the create and update operations and get by order ID [ ] As a manufacturer manager I want to read the status of an order given its order id and receive a report with the full event history of related order, voyage ship and container events. The order id is generated by the order create operation, and is immutable. An order is assigned to a voyage at the time it is created. [ ] As a shipment company manager I want to update the status of an order, and add voyage, container and ship information once I know them, also possible modify pickup date and expected delivery date. [ ] As a shipment manager I want to be able to assign a shipment request from a customer to a specific voyage in order to create a confirmed order. The selected voyage must be from a source port near the pickup location travelling to a destination port near the delivery location requested by the customer. It must be within the time window specified by the customer in the order request. The selected voyage must have free space available ( capacity not previously assigned to other orders) to accomodate the number of containers specified by the customer in their shipment request. Same as above, the UI is in kc-ui project, so here is a model and the update operation.","title":"From analysis to implementation"},{"location":"ddd-applied/#domain-driven-design-applied-to-order-context","text":"During the event storming analysis, we define the domain to be the container shipment domain. It groups a set of subdomains like orders, contract, shipping, and external systems as the voyage scheduling and the container inventory management: Notice that at this time just three physical systems exist. The grouping of the orders, contract and shipping in one boundary context was an analysis shortcut as we want to clearly separate them as the owner ship and ubiquituous language are differents. We have three subdomain and all can be considered core domains. They are competitive advantages and directly impact the organization business. The order subdomain interacts with the contract subdomain via acceptance of the contract conditions from the customer and by build a contract from the created order. When the contract is accepted, the order needs to be shipped, but to do so the shipping subdomain needs to interact with the voyage subsystem to get the available voyage from the closed harbor from the pickup destination, to a target harbor to the shipping destination. It also needs to interact with the container inventory service to get a matching container.","title":"Domain-driven design applied to order context"},{"location":"ddd-applied/#bounded-contexts","text":"Within a business context every use of a given domain term, phrase, or sentence, the Ubiquitous Language inside the boundary has a specific contextual meaning. So order context is a boundary context and addresses order, ordered product type, pickup and shipping addresses. The business problem to address is how to make order traceability more efficient so customers have a clear view of their orders. An order will be assigned to one or many containers and containers are assigned to a voyage.","title":"Bounded Contexts"},{"location":"ddd-applied/#user-stories","text":"The business requirements is presented in this note The following user stories are done in this project: [ ] As a manufacturer manager I want to enter container shipment order information like product reference, quantity, pickup from address, earliest pickup date, shipment to address, shipment by date, and required temperature in transit range so the shipping company can give me back an order confirmation ( including the orderID), expected pickup and delivery dates, the assigned voyage and ship name As the microservice will not have a dedicated UI, we are using the demonstration UI to define forms to gather the data. So this user story is implemented in the kc-ui project, and in this microservice we need to offer the create and update operations and get by order ID [ ] As a manufacturer manager I want to read the status of an order given its order id and receive a report with the full event history of related order, voyage ship and container events. The order id is generated by the order create operation, and is immutable. An order is assigned to a voyage at the time it is created. [ ] As a shipment company manager I want to update the status of an order, and add voyage, container and ship information once I know them, also possible modify pickup date and expected delivery date. [ ] As a shipment manager I want to be able to assign a shipment request from a customer to a specific voyage in order to create a confirmed order. The selected voyage must be from a source port near the pickup location travelling to a destination port near the delivery location requested by the customer. It must be within the time window specified by the customer in the order request. The selected voyage must have free space available ( capacity not previously assigned to other orders) to accomodate the number of containers specified by the customer in their shipment request. Same as above, the UI is in kc-ui project, so here is a model and the update operation.","title":"User stories"},{"location":"deployments/","text":"Deployments Be sure to have read the build and run article before . Deploy locally on Minikube Deploy locally using docker-compose The approach is simple, compile, build the war file, build the docker image and run docker compose for the backend solution. To start the solution go to the refarch-kc/docker folder source ../scripts/setenv.sh LOCAL docker-compose -f kc-solution-compose.yml up Deploy to IKS Deploy to ICP","title":"Kubernetes Deployments"},{"location":"deployments/#deployments","text":"Be sure to have read the build and run article before .","title":"Deployments"},{"location":"deployments/#deploy-locally-on-minikube","text":"","title":"Deploy locally on Minikube"},{"location":"deployments/#deploy-locally-using-docker-compose","text":"The approach is simple, compile, build the war file, build the docker image and run docker compose for the backend solution. To start the solution go to the refarch-kc/docker folder source ../scripts/setenv.sh LOCAL docker-compose -f kc-solution-compose.yml up","title":"Deploy locally using docker-compose"},{"location":"deployments/#deploy-to-iks","text":"","title":"Deploy to IKS"},{"location":"deployments/#deploy-to-icp","text":"","title":"Deploy to ICP"}]}